{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Consider a neuron as a function that tells us a number between 0 and 1. \n",
        "\n",
        "number of neurons = 28*28 = 784\n",
        "\n",
        "0 for black pixels and 1 for white pixels. The number inside the neuron is called the activation.\n",
        "Now the 784 number of neurons containing values from 1 and 0 makes up the first layer of neuron. The last layer has only 10 neurons from 0 to 9. "
      ],
      "metadata": {
        "id": "BsEm7SeQ50x2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Backpropogation**\n",
        "\n",
        "Backpropagation is a popular algorithm used in training neural networks. It involves calculating the **gradient**, which is **a measure of the change in the loss function** with respect to each weight in the network. The **loss function is a measure of how well the neural network is able to predict the correct output for a given input**. By calculating the gradient of the loss function, backpropagation allows the neural network to update its weights in a way that reduces the overall error or loss during training.\n",
        "\n",
        "The algorithm works by propagating the error from the output layer back through the layers of the network, using the chain rule of calculus to calculate the gradient of the loss function with respect to each weight. This gradient is then used in gradient descent optimization to update the weights and minimize the loss function."
      ],
      "metadata": {
        "id": "VZiM8S3XjZ7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " "
      ],
      "metadata": {
        "id": "dbqvUFRLjeD8"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}